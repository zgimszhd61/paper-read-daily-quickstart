论文地址：https://arxiv.org/pdf/2405.18346
全面的临床文档对于有效的医疗服务至关重要，然而它给医护人员带来了巨大负担，导致工作疲劳、增加医疗错误，并危及患者安全。

本文探讨了生成式人工智能（Generative AI）在简化临床文档流程方面的潜力，特别关注生成 SOAP（主观、客观、评估、计划）和 BIRP（行为、干预、反应、计划）笔记。

我们提出了一个案例研究，展示了自然语言处理（NLP）和自动语音识别（ASR）技术在转录患者-临床医生互动方面的应用，结合先进的提示技术，利用大型语言模型（LLMs）生成草稿临床笔记。

该研究突出了这种方法的好处，包括节省时间、提高文档质量和增强以患者为中心的护理。

此外，我们讨论了伦理考虑因素，如保护患者隐私和解决模型偏见问题，强调在医疗环境中负责任地部署生成式人工智能的必要性。

研究结果表明，生成式人工智能有潜力革新临床文档实践，减轻行政负担，使医护人员能够更多地专注于直接患者护理。



**一、引言**

临床文档是医疗服务的关键组成部分，记录了患者的接诊情况、诊断、治疗计划和进展，然而，文档的耗时性已成为医护人员的重大负担，导致工作疲劳、医疗错误和危及患者安全。

多项研究发现，医生和临床医生每天平均花费两到三个小时处理文档任务，迫切需要创新解决方案来简化这一流程。



生成式人工智能是人工智能的一个分支，专注于根据训练数据生成新内容，具有改变临床文档实践的巨大潜力。

通过利用自然语言处理（NLP）和自动语音识别（ASR）技术，生成式人工智能模型可以转录患者-临床医生的互动，并生成草稿临床笔记，捕捉主观患者信息、客观检查结果、评估和治疗计划。



本文提出了一个案例研究，探讨生成式人工智能在生成 SOAP（主观、客观、评估、计划）和 BIRP（行为、干预、反应、计划）笔记方面的应用，这是两种广泛认可的行为健康相关临床文档格式。

我们展示了使用先进提示技术引导大型语言模型（LLMs）生成基于转录的患者-临床医生互动的全面和结构化临床笔记。



我们还讨论了如何通过增加系统文档数据和额外的音频/视频数据来增强和改进这些格式的临床笔记，以减少准确性问题、错误，并通过整个患者治疗过程改善笔记质量。



**二、先前工作**

多项研究已调查减轻医护人员文档负担、提高临床笔记准确性和质量的方法。

一系列研究专注于利用人工智能（AI）模型自动生成临床笔记。



Kernberg 等人（2023）进行的一项研究评估了 ChatGPT-4 的表现，这是由 OpenAI 基于 GPT-3.5 和 GPT-4 大型语言模型构建的对话式人工智能界面，在模拟患者-医护人员互动的转录基础上生成了 SOAP（主观、客观、评估和计划）笔记。

研究结果显示，AI 模型生成的笔记在错误、准确性和质量上存在显著差异。

平均每个临床案例识别出 23.6 个错误，遗漏是错误的主要类型，占错误的 86%。

值得注意的是，生成的笔记准确性与转录长度和数据元素复杂性呈负相关，表明处理复杂医疗案例可能存在潜在限制。

研究总结指出，AI 生成的临床笔记的质量和可靠性不符合临床使用所需的标准，强调需要进一步研究以解决准确性、变异性和潜在错误问题。


论文地址：https://arxiv.org/pdf/2405.18377
现代大语言模型（LLMs）在解决自然语言处理、复杂推理、情感分析等任务方面的能力非凡，这促使它们被广泛采用。

不幸的是，这些能力伴随着非常高的内存和计算成本，这使得大多数硬件平台无法使用LLMs。

为了缓解这一问题，我们提出了一种有效的方法，基于LLAMA2-7B使用一次NAS（神经架构搜索）来找到帕累托最优网络架构。

具体来说，我们仅对LLAMA2-7B进行一次微调，然后应用基于遗传算法的搜索来找到更小、计算复杂性更低的网络架构。

我们展示了，在某些标准基准任务中，预训练的LLAMA2-7B网络是不必要地庞大和复杂。

更具体地，我们展示了在某些任务中，模型大小减少了1.5倍，吞吐量提高了1.3倍，而准确率几乎没有下降。

除了找到更小、性能更高的网络架构外，我们的方法比某些剪枝或稀疏化技术更有效、更高效地实现了这一目标。

最后，我们展示了量化如何与我们的方法相辅相成，我们找到的网络的大小和复杂性可以通过量化进一步减小。

我们相信我们的工作提供了一种自动创建LLMs的方式，可以在更便宜、更易获得的硬件平台上使用。


论文地址：https://arxiv.org/pdf/2405.18300
训练一个智能体通过优化形态和控制来适应特定任务的方法已经广受关注。

然而，在多智能体竞争场景中是否存在最佳配置和策略仍然是一个难以明确得出结论的问题。

在这种背景下，我们提出了竞争进化（Competevo），在对抗中共同进化智能体的设计和策略。

我们建立了包含三种动物及其进化衍生物的竞技场，将具有不同形态的智能体直接竞争。

结果显示，我们的方法使智能体能够进化出比固定形态智能体更适合战斗的设计和策略，使它们在战斗场景中获得优势。

此外，我们展示了在不对称形态下进行对抗时出现的惊人和令人印象深刻的行为。


论文地址：https://arxiv.org/pdf/2405.18272
自几年前大语言模型（LLMs）崛起以来，元启发式算法（MHS）的研究人员一直在思考如何在他们的算法中以有益的方式利用它们的强大能力。

本文介绍了一种新颖的方法，利用LLMs作为模式识别工具来改进MHS。

在基于社交网络的组合优化问题的背景下测试后，所得到的混合方法在解决方案质量方面优于现有将机器学习与MHS相结合的最先进方法。

通过精心设计提示，我们证明了从LLMs获得的输出可以作为问题知识使用，从而带来改进的结果。

最后，我们承认LLMs的潜在缺点和局限性，并认为审查它们对于推进这类研究至关重要。


论文地址：https://arxiv.org/pdf/2405.18208
近期研究突出了大语言模型 (LLM) 擅长一些简单任务，如写作和编码，通过各种推理策略。

然而，LLM 智能体在需要全面规划的任务上仍然面临困难，这一过程挑战着当前模型，并仍然是一个关键的研究问题。

在这项研究中，我们专注于旅行规划，这是一个多阶段规划问题，涉及多个相互关联的阶段，如概述、信息收集和规划，通常需要处理各种约束和不确定性。

现有的推理方法在有效解决这一复杂任务上一直面临困难。

我们的研究旨在通过为LLM智能体开发类人规划框架来解决这一挑战，即指导LLM智能体模拟人类解决多阶段问题时采取的各种步骤。

具体而言，我们实施了几种策略，使LLM智能体能够为每个旅行查询生成连贯的概述，模拟人类规划模式。

此外，我们将策略块和知识块整合到我们的框架中：策略块促进信息收集，而知识块为详细规划提供必要信息。

通过大量实验，我们展示了我们的框架显著提高了LLM智能体的规划能力，使它们能够以更高效和更有效的方式处理旅行规划任务。

我们的实验结果展示了所提出框架的出色性能；与部署在GPT-4-Turbo上的基准框架相比，结合GPT-4-Turbo时，性能提升了10倍。


论文地址：https://arxiv.org/pdf/2405.18180
在训练过程中赋予强化学习（RL）智能体安全探索的能力是将RL智能体部署到许多现实场景中的关键障碍。

在未知的黑盒环境中训练RL智能体时，当领域/任务的先验知识不可用时，安全风险甚至更大。

我们引入了一种名为建议（Adaptive Shielding with a Contrastive Autoencoder）的新型后盾技术，该技术在训练过程中区分状态-动作对的安全和不安全特征，从而保护RL智能体免受执行可能导致危险结果的行动。

我们对最先进的安全RL探索技术进行了全面的实验评估，结果显示，建议能够显著减少训练过程中的安全违规行为，同时保持竞争性的结果奖励。


论文地址：https://arxiv.org/pdf/2405.18123
现代桌面游戏为多智能体强化学习提供了各种有趣的挑战。

本文介绍了 Pytag，这是一个新框架，支持与桌面游戏框架中实现的大量游戏进行交互。

我们从游戏智能体的角度突出了桌面游戏提供的挑战，以及它们为未来研究提供的机会。

此外，我们还强调了涉及在这些游戏上训练强化学习智能体的技术挑战。

为了探索 Pytag 提供的多智能体环境，我们使用自我对弈训练了流行的近端策略优化强化学习算法，并在一部分游戏上评估了训练出的策略与一些简单智能体以及在桌面游戏框架中实现的蒙特卡洛树搜索的对比效果。



关键词：强化学习，多智能体，桌面游戏，棋盘游戏，基准

I. 引言
在过去的十年中，强化学习被证明是一种强大的范式，在围棋[1]和复杂视频游戏[2]中击败了世界冠军。

许多成功案例都是在传统棋盘游戏、纸牌游戏和视频游戏上取得的。

现代桌面游戏（TTGs）经常被忽视，主要是因为缺乏一个统一的框架来支持其研究。

以前，为了研究目的，已经实现了一些独立的现代 TTGs，比如《卡坦岛》[4]和《华丽》[5]，但它们都使用自己的接口和方法，没有直接的兼容性。

为了解决这个问题，提出了桌面游戏（TAG）[6]框架，作为一个研究框架，提供一个共享接口来玩和实现 TTGs，目前已经收录了 20 多款游戏。

TAG 上的大部分工作都使用了统计前向规划算法（例如蒙特卡洛树搜索[7]）；由于各种技术挑战和对强化学习算法的支持不足，以前并未采用强化学习（RL）方法。

多智能体强化学习（MARL）[8]涉及多个智能体位于同一环境中相互竞争、合作以实现共同目标或两者兼而有之。

推进 MARL 方法具有各种潜在的现实应用，因为许多这些问题可以自然地描述为多智能体系统：机器人技术、自动驾驶汽车、视频游戏以及大多数桌面游戏。

在过去的十年里，现代棋盘游戏行业迅速增长，每年都会出版更多的游戏。

现代 TTGs 设计为 2位及以上玩家进行，玩家之间有不同类型的互动。

这些游戏可以是竞争性的，玩家互相竞赛以最先达到游戏的获胜条件，也可以是完全合作的，比如《瘟疫》（Pandemic），玩家必须共同努力才能获胜。

许多游戏既有竞争性又有合作性；玩家可能会暂时结成联盟阻止另一位玩家获胜。

在我们之前的工作中[10]，我们介绍了 Pytag，这是一个 Python API，支持在桌面游戏（TAG）框架提供的游戏中进行强化学习。

我们的初步工作探讨了训练强化学习智能体对抗两个简单基线智能体的可能性：一个随机智能体（以均匀概率抽样动作）和一步先行智能体（OSLA；利用游戏的前向模型，尝试所有可用动作并选择导致最高评估分数的动作）。

针对这些特定对手的训练作为概念验证，证明了有可能让强化学习智能体玩这些游戏，但并没有完全捕捉到游戏呈现的多智能体动态。

在先前的设置中，对手可以被视为环境的一部分，这允许训练单智能体强化学习算法对抗它们。

MARL 设置的主要挑战之一是需要能够适应不同的游戏风格和策略，这之前并未探讨。

为了扩展我们之前的工作，在本文中我们进一步探索了 TTGs 的 MARL 设置，通过引入自我对弈设置来训练 Pytag 中的强化学习智能体，并描述由此产生的技术挑战。

通过使用自我对弈，与基线智能体的比较更加公平。

为了评估训练出的智能体，我们定期对学习智能体进行快照，并与随机智能体、OSLA 和蒙特卡洛树搜索进行评估。

除了自我对弈，我们还添加了两款新游戏：“寿司转转！”（见图 1）和“点与线”。

《寿司转转！》是一款有趣的战略集卡牌游戏，其中未知信息的程度随时间减少。

《点与线》是一款比之前包含的更复杂的完全信息游戏，具有具有欺骗性的短期奖励。

总的来说，Pytag 提供了一个 Python 接口，用于实现强化学习智能体玩桌面游戏框架中实现的游戏。

Pytag 和 TAG 之间的通信是通过共享内存位置来支持快速高效地运行游戏。

TTGs 有多种形式，这使得设计一个能够捕捉所有形式的通用表示变得困难，因此我们提出了接口来支持处理它们的观察和动作。


论文地址：https://arxiv.org/pdf/2405.18118
ERROR:https://arxiv.org/pdf/2405.18118
论文地址：https://arxiv.org/pdf/2405.18092
这篇论文介绍了一个新颖的多智能体系统框架设计，应用了大语言模型（LLM）来自动化数字孪生中过程模拟的参数化。

我们提出了一个包括观察、推理、决策和总结四种类型智能体的多智能体框架。

通过实现LLM智能体与模拟模型之间的动态交互，所开发的系统能够自动探索模拟的参数化，并利用启发式推理确定一组参数来控制模拟以达到一个目标。

所提出的方法通过将LLM的启发式融入模拟模型，增强了模拟模型，并实现了对可行参数化的自主搜索以解决用户任务。

此外，该系统有潜力提高用户友好性，减少人类用户在复杂决策过程中的认知负荷，通过协助复杂决策过程。

系统的有效性和功能通过一个案例研究进行了展示，可在GitHub存储库中查看可视化演示：https://github.com/yuchenxia/llmdrivensimulation。

关键词：大语言模型，多智能体系统，数字孪生，模拟，智能自动化。


论文地址：https://arxiv.org/pdf/2405.17927
这项工作独特地识别和描述了当今多模态领域中四种流行的模型架构模式。

通过按照架构类型系统地对模型进行分类，有助于监测多模态领域的发展。

与最近的综述论文不同，这项研究对架构细节进行了全面探索，并确定了四种特定的架构类型。

这些类型通过各自的方法将多模态输入集成到深度神经网络模型中而有所区别。

前两种类型（类型 a 和 b）在模型的内部层深度融合多模态输入，而后两种类型（类型 c 和 d）在输入阶段促进早期融合。

类型 a 使用标准的交叉注意力，而类型 b 则利用自定义设计的层在内部层进行模态融合。

另一方面，类型 c 使用模态特定的编码器，而类型 d 则利用分词器在模型的输入阶段处理模态。

这些确定的架构类型有助于监测任意到任意多模态模型的发展。

值得注意的是，目前在构建任意到任意多模态模型时，类型 c 和类型 d 受到青睐。

类型 c 以其非分词多模态模型架构而著称，正逐渐成为类型 d 的可行替代方案，后者利用输入分词技术。

为了帮助模型选择，这项工作根据数据和计算需求、架构复杂性、可扩展性、添加模态的简化、训练目标以及任意到任意多模态生成能力，突出了每种架构类型的优缺点。

∗该工作与亚马逊的职位无关。

预印本.arxiv:2405.17927v1 [cs.ai] 2024年5月28日
论文地址：https://arxiv.org/pdf/2405.17739
转载需注明出处。

未经许可，不得复制或转载到服务器或列表，需事先获得特定许可和/或支付费用。

请向permissions@acm.org请求权限。

©2024 版权由所有者/作者所有。

出版权许可给了 ACM。

手稿提交给 ACM 1arxiv:2405.17739v1 [cs.ai]，2024 年 5 月 28 日。


论文地址：https://arxiv.org/pdf/2405.17706
在这项工作中，我们提出使用“对齐视觉字幕”作为一种机制，将视频中包含的信息整合到检索增强生成（RAG）型聊天助手系统中。

这些字幕能够描述大语料库中视频的视觉和音频内容，具有以文本格式呈现的优势，易于推理和融入大语言模型（LLM）提示，同时允许制作数字或纸质副本，供个人或课堂使用，无需支付费用，前提是副本不得用于盈利或商业用途，并且副本必须标明本通知和第一页的完整引用。

必须尊重本作品第三方组件的版权。

对于其他用途，请联系所有者/作者。

MRR 2024年7月18日，华盛顿特区，©2024版权由所有者/作者持有。

通常需要较少的多媒体内容插入到多模态LLM上下文窗口中，典型配置可以通过从源视频采样视频帧来积极填充上下文窗口。

此外，视觉字幕可以通过提示原始基础模型/字幕生成器获取特定的视觉细节或进行微调，以适应特定用例。

为了推动该领域的进展，我们策划了一个数据集，并描述了常见RAG任务的自动评估程序。

CCS概念•信息系统→信息检索；•计算方法→基于视觉内容的索引和检索。

arXiv:2405.17706v1 [cs.ai]，2024年5月27日。


论文地址：https://arxiv.org/pdf/2405.17637
在商业环境中选择语言模型需要仔细分析投资的最终财务收益。

然而，学术界和工业界对大语言模型的分析仅仅集中在性能上。

本文引入了一个评估大语言模型的框架，侧重于应该在商业决策中考虑的收益和投资回报方面。

我们采用决策理论方法比较不同大语言模型的财务影响，考虑诸如每个 Token 成本、在特定任务中成功的概率，以及与大语言模型使用相关的收益和损失等变量。

研究揭示了更昂贵模型的卓越准确性如何在某些条件下可以通过更显著的收益来证明更大的投资，但不一定会带来更高的投资回报率。

本文为希望优化其技术选择的公司提供了一个框架，确保对尖端技术的投资与战略财务目标保持一致。

此外，我们讨论了运营变量的变化如何影响使用大语言模型的经济性，为企业环境提供了实用见解，发现预测的收益和损失以及不同成功和失败概率是影响模型敏感性最大的变量。


论文地址：https://arxiv.org/pdf/2405.17533
产品属性提取是电子商务业务中一个不断发展的领域，具有多种应用，包括产品排名、产品推荐、未来的产品组合规划以及改善在线购物客户体验。

了解客户需求是在线业务的关键部分，尤其是对于时尚产品。

零售商使用产品组合规划来确定每个店铺和渠道提供的产品组合，以保持对市场动态的响应，并管理库存和目录。

其目标是通过正确的渠道提供合适的款式、尺码和颜色。

当购物者找到满足其需求和欲望的产品时，他们更有可能返回进行未来购买，从而促进客户忠诚度。

产品属性是组合规划中的关键因素。

本文介绍了 PAE，一种用于未来趋势报告的产品属性提取算法，其中包含 PDF 格式的文本和图像。

大多数现有方法侧重于从标题或产品描述中提取属性，或利用现有产品图像的视觉信息。

与先前的工作相比，我们的工作侧重于从解释即将到来的时尚趋势的 PDF 文件中提取属性。

本文提出了一个更全面的框架，充分利用不同的模态进行属性提取，并帮助零售商提前规划产品组合。

我们的贡献有三个方面：(a) 我们开发了 PAE，一个从非结构化数据（文本和图像）中提取属性的高效框架；(b) 我们提供基于 BERT 表示的目录匹配方法，以发现使用即将到来的属性值的现有属性；(c) 我们进行了大量实验，与几种基线进行比较，并展示了 PAE 是一种有效、灵活且与现有最先进技术相当或更优秀（平均 92.5% 的 F1 分数）的属性值提取任务框架。

索引词：属性提取、PDF 文件、BERT 嵌入、标签、大语言模型（LLM）、文本和图像。


论文地址：https://arxiv.org/pdf/2405.18406
近期的视频生成模型主要依赖精心编写的文本提示来完成特定任务，比如修复图像或风格编辑。

它们需要耗费大量人力编写输入视频的文本描述，限制了它们适应个人/原始视频规格的灵活性。

本文提出了 Raccoon，一个多才多艺且用户友好的视频-段落-视频生成框架，支持多种视频编辑功能，如删除、添加和修改，通过一个统一的流程。

Raccoon 包括两个主要阶段：视频到段落（V2P）和段落到视频（P2V）。

在 V2P 阶段，我们自动用结构良好的自然语言描述视频场景，捕捉整体背景和重点对象细节。

随后，在 P2V 阶段，用户可以选择性地优化这些描述以指导视频扩散模型，实现对输入视频的各种修改，比如删除、更改主体和/或添加新对象。

所提出的方法通过几个重要贡献脱颖而出：（1）Raccoon 提出了一种多粒度时空池化策略，生成结构良好的视频描述，捕捉广泛背景和对象细节，无需复杂的人类注释，简化了基于文本进行精确视频内容编辑的过程。

 （2）我们的视频生成模型融入了自动生成的叙事。

 ∗同等贡献。

arxiv:2405.18406v1 [cs.cv] 2024年5月28日。


论文地址：https://arxiv.org/pdf/2405.18369
大语言模型（LLMs）已经在各个领域彻底改变了人工智能，展示出令人瞩目的能力。

它们成功的核心在于提示（prompting）的概念，这指导了模型输出的生成。

然而，手动提示工程是劳动密集且领域特定的，需要自动化解决方案。

本文介绍了 PromptWizard，这是一个利用LLMs迭代合成和优化针对特定任务的提示的新框架。

与现有方法不同，PromptWizard 优化了提示指令和上下文示例，最大化了模型性能。

该框架通过变异指令并引入负面示例来迭代优化提示，以加深理解并确保多样性。

它进一步借助评论家增强了指令和示例，合成了富含详细推理步骤以实现最佳性能的新指令和示例。

PromptWizard 提供了几个关键功能和能力，包括与最先进方法相比的计算效率、适应各种训练数据量的场景以及对较小的LLMs的有效性。

在8个数据集上对35个任务进行了严格评估，展示了 PromptWizard 在优化提示方面优于现有提示策略，展示了其在提示优化方面的功效和可扩展性。


论文地址：https://arxiv.org/pdf/2405.18289
学习来自一组策略收集的多步离线数据是强化学习（RL）的核心问题。

基于重要性采样（IS）的方法通常由于IS比例的乘积而遭受较大的方差。

典型的无IS方法，如n步Q学习，沿着动作轨迹向前看n个时间步（其中n被称为前瞻深度），直接利用离线数据而无需额外调整。

对于适当选择的n，它们表现良好。

然而，我们发现这种无IS方法低估了最优值函数（VF），特别是对于较大的n，限制了它们有效利用来自遥远未来时间步的信息的能力。

为了克服这个问题，我们引入了一种新颖的、无IS的多步离线方法，避免了低估问题，并收敛到最优VF。

其核心是一个简单但非平凡的高速公路门，通过将来自遥远未来的信息与阈值进行比较来控制信息流。

高速公路门确保了对于任意n和任意行为策略的最优VF的收敛。

它产生了一类新颖的离线RL算法，即使n很大，也能安全学习，促进了从远期到过去的快速信用分配。

在具有极大延迟奖励的任务中，包括视频游戏，奖励仅在游戏结束时给出，我们的新方法胜过许多现有的多步离线算法。


论文地址：https://arxiv.org/pdf/2405.18110
在多智能体强化学习（MARL）中，有效的探索至关重要，特别是在奖励稀疏的环境中。

尽管引入全局内在奖励可以促进这种情况下的探索，但往往会使代理之间的信用分配变得复杂。

为了解决这一困难，我们提出了个体贡献作为内在探索支架（ICES），这是一种通过从全局视角评估每个代理的贡献来激励探索的新方法。

具体来说，ICES利用贝叶斯惊奇构建探索支架，在集中式训练期间利用全局转移信息。

这些支架仅在训练中使用，有助于引导个体代理朝向对全局潜在状态转移产生显著影响的动作。

此外，ICES将探索策略与利用策略分离，使前者能够在训练期间利用特权全局信息。

在包括Google Research Football（GRF）和StarCraft多智能体挑战（SMAC）在内的合作基准任务上进行了大量实验，结果表明ICES相对于基线表现出更优秀的探索能力。

代码公开可在 https://github.com/lxxxxr/ices 获取。


论文地址：https://arxiv.org/pdf/2405.18068
推荐系统在数字时代是不可或缺的工具，在电子商务、娱乐和社交媒体等领域为用户提供个性化内容。

在众多开发这些系统的方法中，潜在因子模型被证明特别有效。

本调查系统地审视了推荐系统中的潜在因子模型，重点关注它们的核心原理、方法论和最新进展。

通过一个结构化框架，对文献进行了审查，涵盖学习数据、模型架构、学习策略和优化技术。

分析包括对贡献的分类法和对使用的学习数据类型的详细讨论，如隐式反馈、信任和内容数据，各种模型，如概率、非线性和神经模型，以及对在线学习、迁移学习和主动学习等多样化学习策略的探索。

此外，调查还涉及用于训练潜在因子模型的优化策略，以提高其性能和可扩展性。

通过识别趋势、差距和潜在研究方向，本调查旨在为希望推进推荐系统领域的研究人员和从业者提供有价值的见解。

关键词：个性化推荐、隐式反馈、信任数据、非线性模型、深度神经网络、自监督学习、迁移学习、优化技术、随机梯度下降、数据稀疏性、可扩展性

✦ 1 引言
在数字时代，推荐系统是不可或缺的。

它们在过滤大量数据以向用户提供个性化内容方面发挥着至关重要的作用。

这些系统帮助用户在产品选择、电影偏好和音乐发现等各个领域做出明智选择。

通过利用历史数据和上下文信息预测用户偏好，推荐系统提升了用户满意度和参与度。

潜在因子模型已成为构建推荐系统的高效方法。

这些模型利用矩阵分解技术的潜力来捕捉用户-物品交互中的潜在模式。

通过在共享的潜在空间中表示用户和物品，它们解决了推荐任务中固有的稀疏性和可扩展性挑战。

学习数据模型优化学习策略训练模型推荐图
论文地址：https://arxiv.org/pdf/2405.18044
认知能力，比如心灵理论 (Theory of Mind, TOM)，在促进人类社会互动中的合作中扮演着至关重要的角色。

然而，我们的研究发现，具有较高 TOM 能力的智能体不一定比那些 TOM 能力较低的智能体表现出更好的合作行为。

为了解决这一挑战，我们提出了一种新颖的匹配联盟机制，通过明确考虑信念一致性和专业能力，在形成联盟时充分利用具有不同 TOM 水平的智能体的优势。

我们提出的匹配算法旨在找到最大化合作行为潜力并确保长期生存能力的稳定联盟。

通过将认知洞察力融入多智能体系统的设计中，我们的工作展示了利用 TOM 创造更复杂和类人协调策略的潜力，促进合作并提高整体系统性能的可能性。


论文地址：https://arxiv.org/pdf/2405.17998
最近，研究人员发现神经检索模型更倾向于人工智能生成内容（AIGC），这被称为来源偏见 [10,40]。

与主动搜索行为相比，推荐代表了另一种重要的信息获取方式，用户更容易受到来源偏见的影响。

此外，深入研究推荐场景时，随着AIGC被整合到涉及用户、数据和推荐系统的反馈循环中，它逐渐污染了候选项、用户互动历史，最终影响了用于训练推荐模型的数据。

来源偏见如何以及在多大程度上影响神经推荐模型在反馈循环中仍然是未知的。

在本研究中，我们将来源偏见的调查扩展到推荐系统领域，具体考察其在反馈循环的不同阶段的影响。

我们将AIGC整合到推荐内容生态系统中的进展概念化为三个明显阶段——HGC 主导、HGC-AIGC 共存和AIGC 主导——分别代表过去、现在和未来状态。

通过在来自不同领域的三个数据集上进行广泛实验，我们展示了来源偏见的普遍存在，并揭示了一个潜在的数字回音室，其中来源偏见在整个反馈循环中被放大。

这种趋势可能会导致一个推荐生态系统，其中被推荐的信息源受到限制，例如AIGC。

为了抵消这种偏见并防止其在反馈循环中升级，我们提出了一种黑盒去偏方法，使模型对HGC和AIGC保持公正。

我们的实验结果验证了所提出的去偏方法的有效性，证实了其打破反馈循环的潜力。

未经许可，可以制作本作品的全部或部分数字或纸质副本供个人或课堂使用，但不得为盈利或商业优势而制作或分发副本，并且副本必须带有本通知和第一页的完整引用。

对于本作品的组成部分的版权归其他人所有的情况，必须尊重版权。


论文地址：https://arxiv.org/pdf/2405.17974
在对话系统中通过个性化提升用户参与度变得越来越重要，尤其是随着能够生成流畅回复的大语言模型的出现。

然而，个性化对话生成是一个多方面的概念，其定义各有不同，从在智能体中注入个人特质到捕捉用户的明示和暗示线索不等。

本文旨在系统地调查最近个性化对话生成的现状，包括所使用的数据集、开发的方法以及应用的评估指标。

涵盖了22个数据集，我们重点介绍了基准数据集和一些新增功能丰富的新数据集。

我们进一步分析了从2021年到2023年间在顶级会议上发表的17篇重要作品，并确定了五种不同类型的问题。

我们还着重介绍了大语言模型在个性化对话生成方面的最新进展。

我们的评估部分提供了这些作品中使用的评估方面和指标的全面总结。

最后，我们讨论了个性化对话系统中当前面临的挑战，并展望了未来研究的发展方向。

关键词：个性化对话系统，个性化回复生成，基于人物的对话
论文地址：https://arxiv.org/pdf/2405.17935
最近，利用大语言模型（LLMs）进行工具学习已经成为增强LLMs能力以解决高度复杂问题的一种有前景的范式。

尽管这一领域受到越来越多的关注并取得了快速进展，但现有文献仍然零散且缺乏系统性组织，给新手带来了进入障碍。

这一空白激励我们进行一项关于利用LLMs进行工具学习的现有研究的全面调查。

在这项调查中，我们专注于从两个主要方面审查现有文献：（1）为什么工具学习有益以及（2）工具学习如何实施，从而实现对利用LLMs进行工具学习的全面理解。

我们首先通过审查工具整合的益处以及工具学习范式的固有益处的六个具体方面，探讨“为什么”。

在“如何”方面，我们根据工具学习工作流程中的四个关键阶段的分类法，系统地审查文献：任务规划、工具选择、工具调用和响应生成。

此外，我们根据它们与不同阶段的相关性对现有基准和评估方法进行了详细总结。

最后，我们讨论当前的挑战并概述潜在的未来方向，旨在激励研究人员和工业开发者进一步探索这一新兴且有前景的领域。


论文地址：https://arxiv.org/pdf/2405.17940
智能视觉控制系统用于外科机器人应当能够适应未知和多样化的物体，同时对系统干扰具有鲁棒性。

之前的方法主要依赖于姿态估计和特征跟踪，未能满足这些要求。

我们提出了一个基于世界模型的深度强化学习框架“手术抓取任何物体”（Grasp Anything for Surgery，简称 GAS），该框架学习了用于外科抓取的像素级视觉运动策略，增强了泛化性和鲁棒性。

具体来说，我们提出了一种新方法，基于物体尺寸的经验先验，估计了刚性链接物体不准确区域深度像素的值和不确定性；任务物体的深度和掩模图像被编码成一个紧凑的三通道图像（尺寸：64x64x3），通过动态缩放掩模区域，最小化信息丢失。

我们在仿真环境和真实机器人中广泛评估了学习到的控制器的有效性。

我们学习到的视觉运动策略处理了：i）未见过的物体，包括5种目标抓取物体和一个机器人夹具，在非结构化的真实世界手术环境中，以及 ii）感知和控制中的干扰。

值得注意的是，我们是第一个在复杂手术场景中使用不同机器人夹具在真实机器人上抓取多样化手术物体的统一手术控制系统（平均成功率：69%）。

我们的系统还在包括背景变化、目标干扰、摄像头姿态变化、运动控制误差、图像噪声以及夹持目标物体掉落后重新抓取等6种条件下展现了显著的鲁棒性。

视频和代码可在我们的项目页面找到：https://linhongbin.github.io/gas/。



**i. 引言**

在机器人辅助手术（RAS）中自动化繁琐重复的抓取任务可以显著减轻外科医生的身体和精神疲劳。

常见的手术任务包括抓取针头、纱布、海绵、线等物体，以及去除坏死组织等过程。

传统解决方案首先从观察到的摄像头图像中估计与任务相关物体的笛卡尔姿态，然后操作目标物体。

因此，这些方法对姿态估计误差不具有鲁棒性，可能导致抓取失败，甚至造成灾难性后果。

在[19]中，系统直接跟踪观察图像的特征坐标以增加视觉鲁棒性，而不是进行物体姿态估计。

然而，姿态估计和特征跟踪方法都需要完整的几何模型或者假设几何形状来推断任意点位置的信息。

因此，在非结构化环境中在线适应未见过的物体是困难的。

为了弥合研究和实际手术应用之间的差距，我们旨在增强：i）在非结构化环境中未见过物体的泛化能力，以及 ii）机器人在感知和配置干扰方面的鲁棒性。


论文地址：https://arxiv.org/pdf/2405.17846
各行业中服务机器人的安全限制引起了人们对确保机器人遵守安全规范的强烈关注，从而防止可能对人类造成伤害或财产损失的行为。

尽管包括将知识图谱 (Knowledge Graphs, KGs) 与大语言模型 (Large Language Models, LLMs) 整合在内的进展，但在确保自主机器人行为一致安全方面仍存在挑战。

本文提出了一种新颖的方法，将大语言模型与具身体控制提示 (Embodied Robotic Control Prompts, ERCPs) 和具身体知识图谱 (Embodied Knowledge Graphs, EKGs) 相结合，以增强服务机器人的安全框架。

ERCPs 被设计为预定义指令，确保LLMs生成安全且精确的响应。

这些响应随后由EKGs验证，提供全面的知识库，确保机器人的行动持续符合安全协议，从而促进各种情境下更安全的操作实践。

我们的实验设置涉及各种真实世界任务，配备我们框架的机器人表现出比传统方法显著更高的安全标准合规性。

这种整合促进了安全的人机交互，并将我们的方法学置于服务机器人领域AI驱动安全创新的前沿。



关键词：大语言模型、具身体控制提示、具身体知识图谱、服务机器人、安全控制

I. 引言
服务机器人已被部署在各个领域，包括医疗辅助、客户服务增强和物流操作。

它们融入以人为中心的环境中引入了重大的安全挑战，需要对其操作可靠性和任务执行安全进行严格审查。

解决这些安全挑战对于将服务机器人建立为可靠的AI合作伙伴至关重要。

已经开发了各种方法，包括使用大语言模型和知识图谱来指导服务机器人的行为。

然而，仅使用LLMs在服务机器人中存在显著局限性。

LLMs擅长自然语言处理，但往往无法在现实环境中对信息进行上下文化和提供事实信息，导致在复杂情况下产生不当响应。

另一方面，知识图谱使服务机器人能够访问和利用大量的事实和结构化信息，增强其决策过程。

然而，单独使用KGs无法处理自然语言或非结构化数据的细微差别，限制了其在各种交互场景中的适用性。

认识到LLMs和KGs的互补优势，最近的研究探讨了通过将LLMs的自然语言能力与KGs的结构化事实知识相结合来整合它们。

当这些技术整合时，服务机器人能够更好地理解人类语言并访问相关上下文信息。

我们的研究提出了一种超越传统LLMs和KGs整合的新方法。

我们引入了专门为服务机器人设计的具身体控制提示和具身体知识图谱。

ERCPs是定制的提示模板，旨在帮助LLMs生成一致的服务机器人操作任务计划。

EKGs是我们框架的核心，验证LLMs生成的任务计划，并提供全面的事实信息，以确保服务机器人的安全运行。



A. 问题陈述
核心问题在于服务机器人安全行为和操作可靠性的局限性。

缺乏实时验证机制、事实信息和逻辑推理能力，阻碍了这些机器人在复杂的现实场景中以最佳和安全的方式运行。

为了解决这些限制，我们提出了一种在未知环境中处理复杂任务高效的解决方案：
- 我们提出为服务机器人使用定制提示模板：具身体控制提示 (ERCPs)。


- 我们提出使用具身体知识图谱 (EKGs) 来指导LLMs为服务机器人输出，并为安全任务完成提供全面的事实信息。


- 我们提出将LLMs与ERCPs和EKGs整合，以确保服务机器人的安全运行。


论文地址：https://arxiv.org/pdf/2405.17465
食品生产是全球关注的重要问题，人工智能（AI）在农业技术革命中的潜力仍然大部分未被探索。

本文提出了一项专注于机器学习（ML）在农业中应用的综合性回顾，旨在探索其在农业实践和效率提升中的变革潜力。

为了了解该领域的研究活动程度，我们收集了统计数据，揭示了近年来显著增长的趋势。

这表明它是最具活力和动态性的研究领域之一。

通过介绍ML的概念，并深入探讨智慧农业领域，包括精准农业、智慧农业、数字农业和农业4.0，我们探讨了AI如何优化作物产量并减少环境影响。

我们强调ML分析和分类农业数据的能力，提供了农场生产力和盈利能力提升的例子。

此外，我们讨论了在农业应用中表现出有希望结果的突出ML模型及其独特特点。

通过系统回顾文献，本文填补了农业领域AI研究的现有文献空白，并为新手和研究人员提供了有价值的信息。

通过揭示这一新兴领域内尚未开发的领域，我们的目标是促进对AI在农业中的重要贡献和潜力的更深入理解，最终使研究社区受益。

关键词：农业，人工智能（AI），机器学习（ML），精准农业，智慧农业，数字农业。
